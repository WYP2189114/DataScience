{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'type_check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b8108de38d19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 引用packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[1;31m# NOTE: to be revisited following future namespace cleanup.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;31m# See gh-14454 and gh-15672 for discussion.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\lib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'emath'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'math'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tracemalloc_domain'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Arrayterator'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0m__all__\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtype_check\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mindex_tricks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfunction_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__all__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'type_check' is not defined"
     ]
    }
   ],
   "source": [
    "# 引用packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料前處理\n",
    "# 讀取train_data(正式版)\n",
    "train_data = pd.read_csv('./data/train.csv') \n",
    "\n",
    "# 將連續型資料標準化並傳回train_data \n",
    "train_standard = train_data[['CreditScore', 'Balance', 'EstimatedSalary']]\n",
    "z_scaler = StandardScaler()\n",
    "# z_scaler = Normalizer()\n",
    "z_scaler.fit(train_standard)\n",
    "train_standard_scaled = z_scaler.transform(train_standard)\n",
    "train_standard_scaled = pd.DataFrame(train_standard_scaled, columns=['CreditScore', 'Balance', 'EstimatedSalary'])\n",
    "train_data['Balance'] = train_standard_scaled['Balance']\n",
    "train_data['EstimatedSalary'] = train_standard_scaled['EstimatedSalary']\n",
    "train_data['CreditScore'] = train_standard_scaled['CreditScore']\n",
    "\n",
    "train_features = train_data\n",
    "#去除超過3個標準差的離群值(全部經標準化欄位)\n",
    "# train_features = train_data[abs(train_data['CreditScore'])<3]\n",
    "# train_features = train_features[abs(train_features['Balance'])<3]\n",
    "# train_features = train_features[abs(train_features['EstimatedSalary'])<3]\n",
    "\n",
    "# 將非數值資料轉換為數值\n",
    "train_features_drop = train_features.drop(['RowNumber','CustomerId', 'Surname', 'Exited'],axis=1)\n",
    "train_features_sub = pd.get_dummies(train_features_drop)\n",
    "\n",
    "# 建立train_data的類別值與資料\n",
    "train_data_class = train_features['Exited'].values \n",
    "train_data_sub = train_features_sub.values\n",
    "\n",
    "\n",
    "# 讀取test_data\n",
    "test_data = pd.read_csv('./data/test.csv') \n",
    "\n",
    "# 將連續型資料標準化並傳回test_data \n",
    "test_standard = test_data[['CreditScore', 'Balance', 'EstimatedSalary']]\n",
    "test_standard_scaled = z_scaler.transform(test_standard)\n",
    "test_standard_scaled = pd.DataFrame(test_standard_scaled, columns=['CreditScore', 'Balance', 'EstimatedSalary'])\n",
    "test_data['Balance']  = test_standard_scaled['Balance']\n",
    "test_data['EstimatedSalary']  = test_standard_scaled['EstimatedSalary']\n",
    "test_data['CreditScore']  = test_standard_scaled['CreditScore']\n",
    "\n",
    "# 將非數值資料轉換為數值\n",
    "test_features = test_data.drop(['RowNumber','CustomerId', 'Surname'],axis=1)\n",
    "test_features_sub = pd.get_dummies(test_features)\n",
    "test_data_sub = test_features_sub.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# 從train_data中切訓練資料\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_data_sub, train_data_class, \n",
    "                                                    train_size=0.75, \n",
    "                                                    random_state=123)\n",
    "\n",
    "resampled_x, resampled_y = SMOTE(kind='borderline1').fit_sample(train_x, train_y)\n",
    "\n",
    "# 利用遞迴找到 max_depth最佳參數\n",
    "max_parameters=[0,0,0,0,0,0]\n",
    "for x in range(3,11):\n",
    "    \n",
    "    # 建立 XGBClassifier 模型\n",
    "    xgb_Model = XGBClassifier(n_estimators=200, max_depth= x, use_label_encoder =False, eval_metric=\"error\")\n",
    "    outcomes = xgb_Model.fit(train_x, train_y).predict(test_x)\n",
    "\n",
    "    # 計算Accuracy, Precision & Recall\n",
    "    accuracy = xgb_Model.score(test_x, test_y)\n",
    "    precision = precision_score(test_y, outcomes, average='binary')\n",
    "    recall = recall_score(test_y, outcomes, average=None)\n",
    "    f_score = (2*precision*recall[1]) / (precision+recall[1])\n",
    "    score = 0.3*accuracy + 0.3*precision + 0.4*f_score\n",
    "\n",
    "    if score > max_parameters[0]:\n",
    "        max_parameters[0] = score \n",
    "        max_parameters[1] = x \n",
    "    elif score > max_parameters[2]:\n",
    "        max_parameters[2] = score \n",
    "        max_parameters[3] = x\n",
    "    elif score > max_parameters[4]:\n",
    "        max_parameters[4] = score \n",
    "        max_parameters[5] = x\n",
    "        \n",
    "print(max_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 建立 XGBClassifier 模型\n",
    "xgb_Model = XGBClassifier(n_estimators=200, max_depth= 3, use_label_encoder =False, eval_metric=\"error\")\n",
    "outcomes = xgb_Model.fit(train_data_sub, train_data_class).predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(hidden_layer_sizes=(30,10,2),random_state=0)\n",
    "nn.fit(train_data_sub, train_data_class)\n",
    "outcomes = nn.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "classifier = svm.SVC(kernel='linear')\n",
    "classifier.fit(train_data_sub, train_data_class)\n",
    "outcomes = classifier.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier(n_neighbors=5)\n",
    "knc.fit(train_data_sub, train_data_class)\n",
    "outcomes = knc.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_data_sub, train_data_class)\n",
    "outcomes = classifier.predict(test_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料寫入csv檔\n",
    "test_data_class = pd.Series(outcomes)\n",
    "test_df = pd.DataFrame({'RowNumber':test_data['RowNumber'], 'Exited':test_data_class})\n",
    "test_df.to_csv('./data/xgboost(200&3).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
